\chapter{Svolgimento dello \textit{stage}}
    \section{Conoscenza del dominio di applicazione}
    La fase iniziale del progetto ha previsto un'immersione approfondita nel dominio applicativo, costituito da un ecosistema manifatturiero dedicato alla produzione di beni per aziende terze. Il sistema in esame si configura come una soluzione trasversale e implementabile in molteplici realtà produttive che adottano metodologie operative simili. L'architettura attuale è basata sulla piattaforma SAI, mentre l'obiettivo dello \textit{stage} è stato quello di condurre un'analisi completa finalizzata alla rimodellazione del dominio.

    \vspace{0.2 em}
    \noindent Le caratteristiche principali del sistema attuale sono:

    \begin{itemize}
        \item \textbf{tracciabilità delle risorse umane}: il sistema mantiene un registro completo del personale operativo, con identificazione univoca di ciascun lavoratore all'interno dell'ecosistema informativo;

        \item \textbf{monitoraggio del processo produttivo}: ogni fase della catena di lavorazione è dettagliatamente documentata, con registrazione sistematica dello stato avanzamento lavori per ciascuna operazione in corso;

        \item \textbf{gestione dell'inventario}: implementazione di meccanismi di controllo delle materie prime, con funzionalità di rilevamento delle soglie critiche e conseguente attivazione di processi di approvvigionamento, alcuni dei quali completamente automatizzati;

        \item \textbf{amministrazione integrata}: il sistema incorpora moduli per la gestione contabile, l'elaborazione documentale e la pianificazione logistica del trasporto.

    \end{itemize}
    
    \vspace{0.2 em}
    \noindent Il progetto di \textit{stage} si è focalizzato principalmente sull’analisi approfondita del dominio applicativo, con l’obiettivo di aggiornare e ridefinire il modello esistente. Questo processo ha previsto l’identificazione e la delimitazione dei \textit{bounded contexts} secondo i principi del \textit{Domain-Driven Design}, cercando di mantenere una rappresentazione chiara e coerente delle diverse aree funzionali del sistema. La fase successiva ha riguardato la formalizzazione dei requisiti funzionali e non funzionali, definendo così i confini tecnici e prestazionali necessari per sviluppare un’eventuale reingegnerizzazione del sistema attualmente basato sulla piattaforma SAI. Come anticipato nella Sezione 1.6.2, le situazioni descritte possono costituire un modello di dominio completo.  

    \vspace{0.2 em}
    \noindent L’obiettivo principale del progetto di \textit{stage} era individuare un modello di dominio specifico e svilupparne un prototipo. Dopo un’attenta valutazione, è stato scelto il \textbf{monitoraggio del processo produttivo} come ambito di intervento. Durante il lavoro, ho potuto constatare quanto sia complesso separare completamente i modelli di dominio, poiché alcuni si intersecano inevitabilmente. Questo mi ha portato alla consapevolezza che non esiste una soluzione perfetta in senso assoluto, ma piuttosto un compromesso tra le diverse esigenze e realtà operative. 
    
    
    \section{Attività svolte}
        \subsection{Analisi dei requisiti}
        Tra i vari modelli di dominio individuati, è stato dunque selezionato quello relativo al \textbf{monitoraggio del processo produttivo}, il quale rientra nell’ambito dell’analisi dei requisiti, come descritto nella Sezione 1.6.1. 

        \vspace{0.2 em}
        \noindent L’analisi dei requisiti è stata condotta in collaborazione con il \textit{Product Owner}, partendo dall’esame approfondito della situazione rappresentata nell’Immagine \ref{fig:Dominio}. Tale attività ha permesso di delineare con precisione le necessità operative e gli obiettivi funzionali, costituendo la base per lo sviluppo del prototipo.

        \begin{figure}[H]
            \centering
            \includegraphics[width=0.6\linewidth]{BCS-Tessi//images/Dominio.png}
            \caption[Modello di dominio preso in esame]{Schema visuale del modello di dominio preso in esame durante l'attività di analisi dei requisiti}
            \label{fig:Dominio}
        \end{figure}

        \vspace{0.2 em}
        \noindent L'immagine descrive una situazione reale semplificata con cui l'azienda si interfaccia: la gestione della produzione di un certo \texttt{Articolo} finito, la cui produzione prevede un certo \texttt{CicloDiLavoro} composto da diverse \texttt{Fasi} che sono predefinite. Consideriamo ogni componente corrispondere a un \textit{bounded context}.
        Nello specifico: 
        \begin{itemize}
            \item La produzione di un \texttt{Articolo} richiede un \texttt{OrdineProduzione}, che rappresenta la quantità da produrre e la quantità prodotta.
            \item \texttt{OrdineProduzioneFasi} tiene traccia dello stato di avanzamento della produzione considerando quante unità sono state prodotte in base alla \texttt{Fase} e anche in base ai materiali disponibili. Può infatti succedere che la quantità richiesta non venga raggiunta per mancanza di materiali sufficienti: il conteggio si ferma automaticamente quando il numero di unità è stato raggiunto o manualmente quando le risorse sono state esaurite. Tiene conto della quantità da produrre, della quantità prodotta e dello stato (aperto, in corso, chiuso).
            \item Il riquadro nell'immagine comprende i \textit{bounded context} presi in analisi. Il \texttt{Rilevamento} prevede che ogni lavoratore segnali (attraverso un \textit{badge}) al sistema il momento di inizio del lavoro e il momento della fine dello stesso, con il numero di pezzi prodotti in base alla fase di lavoro corrispondente. Il completamento di una fase di \texttt{Rilevamento} fa avanzare anche \texttt{Lavorazione} che tiene conto della quantità prodotta e della quantità scartata.
            \item Una \texttt{Risorsa} è rappresentata dall'operaio, la macchina che utilizza per la fase determinata, la \texttt{Fase}, il numero di unità prodotte, l'ora di inizio del lavoro e l'ora di fine.
        \end{itemize}

        \vspace{0.2 em}
        \noindent Il problema principale è far comunicare in tempo reale \texttt{Rilevamento} e \texttt{OrdineProduzioneFasi}, senza che quest'ultimo debba essere portato all'interno del microservizio che individuiamo come \texttt{MS\_Rilevamento}.

        \vspace{0.2 em}
        \noindent La soluzione ideale infatti sarebbe quella di includere \texttt{OrdineProduzione} e \texttt{OrdineProduzioneFasi} nell'unico microservizio \texttt{MS\_Rilevamento}. Questo perché secondo i principi del \textit{Domain-Driven Design} la divisione in \textit{bounded contexts} dovrebbe attuare una scomposizione in microservizi che siano poco accoppiati tra di loro. In questo caso invece c'è un alto grado di accoppiamento tra i \textit{bounded context} appena citati e  \texttt{Lavorazione}, quindi scomporli in servizi differenti non è in linea con i principi DDD\footnote{E. Evans, Domain-Driven Design: Tackling Complexity in the Heart of Software, Addison-Wesley, 2003}.

        \vspace{0.2 em}
        \noindent Questa soluzione non è applicabile al momento perché il monolite è strettamente collegato in vari punti con \texttt{OrdineProduzione} e con \texttt{OrdineProduzioneFasi}. La priorità è dunque estrarre \texttt{Rilevamento} e \texttt{Lavorazione} in un unico servizio, e in un secondo momento completare la divisione ideale.

        \subsection{Progettazione}
        Durante il mio \textit{stage}, l’analisi dei requisiti e la fase di progettazione si sono sviluppate in modo parallelo. Con l’aumentare della mia conoscenza del dominio applicativo e l’individuazione dei requisiti, la progettazione, guidata dal \textit{Product Owner}, è avvenuta in modo naturale, senza una netta separazione tra le due attività.  

        \vspace{0.2 em}
        \noindent Poiché la progettazione consiste nel definire come realizzare concretamente quanto emerso dall’analisi dei requisiti, questo capitolo si concentrerà sulla descrizione dei \textit{pattern} identificati e delle soluzioni architetturali adottate per soddisfare i requisiti individuati.

        \vspace{0.2 em}
        \noindent La soluzione individuata è rappresentata nella Figura \ref{fig:progettazione} e rappresenta il modo in cui \texttt{MS\_} \texttt{Rilevamento} potrà comunicare con SAI attraverso un \texttt{MS\_Middleware}. Questo rappresenta molto bene il piano di migrazione visibile nella Figura \ref{fig:migrazione}.
        
        \begin{figure}
            \centering
            \includegraphics[width=0.7\linewidth]{BCS-Tessi//images/Progettazione.png}
            \caption[Progettazione per l'estrazione del microservizio]{Attività di progettazione per quanto concerne l'estrazione di \texttt{MS\_Rilevamento}}
            \label{fig:progettazione}
        \end{figure}

        \vspace{0.2 em}
        \noindent Date le dimensioni molto grandi del monolite in esame, l'azienda ha scelto di optare per una migrazione graduale. La soluzione più ragionevole è risultata dunque quella di applicare il \textit{pattern} \textit{Anti-Corruption Layer} (ACL) prevedendo la lunga convivenza del monolite e del nuovo sistema a microservizi. 

        \vspace{0.2 em}
        \noindent Un altro \textit{pattern} proposto è il \textit{Change Data Capture}, una tecnica utilizzata per identificare e tracciare le modifiche apportate ai dati in un database. Nel nostro caso è utile nei contesti di sincronizzazione tra sistemi eterogenei, ossia di \texttt{MS\_Rilevamento} e di SAI, il monolite. 
        
        E' stato scelto dall'azienda anche il modello di architettura esagonale, noto anche come pattern di porte e adattatori che mira a creare architetture liberamente accoppiate in cui i componenti delle applicazioni possano essere testati in modo indipendente, senza dipendenze da archivi di dati o interfacce utente. Viene utilizzato per isolare la logica aziendale (logica di dominio) dal codice dell'infrastruttura correlato. E' possibile collegare facilmente i componenti della business logic ad altri componenti nell'architettura dell'applicazione tramite porte e adattatori. Le porte sono punti di ingresso indipendenti dalla tecnologia in un componente dell'applicazione. Queste interfacce personalizzate determinano l'interfaccia che consente agli attori esterni di comunicare con il componente dell'applicazione, indipendentemente da chi o cosa implementa l'interfaccia. Gli adattatori interagiscono con l'applicazione tramite una porta utilizzando una tecnologia specifica. Gli adattatori si collegano a queste porte, ricevono o forniscono dati alle porte e li trasformano per un'ulteriore elaborazione. Ad esempio, un REST adattatore consente agli attori di comunicare con il componente dell'applicazione tramite un RESTAPI. Le porte dunque si connettono all'applicazione e gli adattatori fungono da connessione con il mondo esterno. Gli handler sono componenti fondamentali nell'architettura esagonale, poiché gestiscono le richieste di comando e comunicano con il dominio dell'applicazione. Sono classi o metodi che si occupano di eseguire specifiche operazioni sul dominio di applicazione. Queste operazioni possono includere la creazione, la lettura, l'aggiornamento o la cancellazione di dati.

        La progettazione dell'API per un caso d'uso.
        Caso d'uso: Registrazione di una Lavorazione
        Quando viene registrata una lavorazione, il sistema dovrebbe aggiornare automaticamente la quantità prodotta nell'entità OrdineProduzioneFasi. Se lo stato della fase corrispondente risulta "chiuso", l'operazione non deve essere registrata e deve restituire un errore, evitando ulteriori modifiche.
        soluzione webapi n questo approccio, ogni microservizio o componente invia richieste al monolite in maniera sincrona e attende una risposta prima di proseguire. Il flusso di lavoro è bloccante, quindi il servizio attende una risposta dal monolite prima di continuare. Se si verifica un errore (come nel caso in cui la fase sia chiusa), la situazione può essere gestita immediatamente, permettendo di effettuare un rollback e annullare le modifiche già effettuate, ripristinando lo stato precedente. Sebbene questo approccio crei un maggiore accoppiamento tra il microservizio e il monolite, è generalmente più semplice da implementare rispetto alla soluzione basata su sagas.

        Problema: Necessità di dati da due fonti
        MSRILEVAMENTO: serve per verificare se esiste già una lavorazione in corso per quella specifica fase dell'Ordine di Produzione. In tal caso, il sistema dovrebbe proporre automaticamente la lavorazione in corso.
        Monolite: necessario per ottenere informazioni aggiuntive sull'Ordine di Produzione, come il codice, la data prevista di evasione, e i dettagli della fase (es. descrizione e numero della fase).
        In pratica, per completare correttamente questa operazione, è necessario combinare i dati provenienti da entrambi i sistemi: uno per monitorare lo stato attuale della lavorazione e l'altro per accedere ai dati essenziali dell'ordine e della fase da lavorare.
        Soluzione
        Effettuare due letture:
        Una su MSRILEVAMENTO tramite un adapter PostgreSQL su un database locale.
        Una su ERP tramite una connessione PostgreSQL al database del monolite.
        Si propongono due approcci per gestire queste letture:
        Pattern Database View: si crea una vista nel database che unisce i dati da MSRILEVAMENTO e dal monolite. Tuttavia, questo crea un accoppiamento diretto tra il sistema e la struttura del database dell'ERP.Il sistema attualmente adottato per unire questi dati consiste nel prodotto cartesiano sulle tabelle. Questo significa che tutte le combinazioni possibili tra le righe delle due tabelle vengono generate, creando un insieme di dati potenzialmente molto grande. Successivamente, per estrarre le informazioni rilevanti, vengono applicate delle viste. Questo può portare a rallentamenti notevoli, nonché difficoltà nella gestione della complessità dei dati.Una soluzione migliore potrebbe essere applicare il Database Wrapping Service.
        Pattern Database Wrapping Service (Preferibile): si crea un servizio intermedio (wrapping service) che si occupa di esporre le informazioni dell'ERP tramite delle Web API senza esporre direttamente il database sottostante. In questo modo, il team che gestisce l'ERP è responsabile dell’aggiornamento delle API in caso di modifiche alla struttura del database, e il team di MSRILEVAMENTO non deve preoccuparsi dei cambiamenti interni all'ERP. Questo approccio riduce l'accoppiamento tra i sistemi, rendendo più facile l'evoluzione della struttura dei dati.

        Demo debezium per data sincronization 

        
        \subsection{Implementazione}
        Descriverò l'attività di implementazione, riprendendo la sezione relativa nel primo capitolo. 
        Racconterò nel dettaglio i miei \textit{task}, le difficoltà incontrate e le soluzioni ottenute, sia riguardo all'estrazione del microservizio che riguardo la gestione del \textit{database}. 
        Descriverò i \textit{pattern} scelti, come li ho implementati, ed eventuali risultati rilevanti. 

        STRUTTURA DEL CODICE, altri pattern che ho applicato tramite il learn by doing ma non parte del processo di progettazione. 
        Tecnologie utilizzate sono già state approfondite, ma di particolare rilevanza Debezium.

        Ai fini di questa trattazione, come sono state implementate le singole cose non è particolarmente rilevante, nonostante sia entrata in contatto con diversi pattern molto interessanti come: CQRS, DTO. 
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.5\linewidth]{BCS-Tessi//images/code_structure.png}
            \caption{Struttura del codice utilizzata per l'estrazione del microservizio.}
            \label{fig:code-structure}
        \end{figure}

        
        Analizzando più approfonditamente la struttura del microservizio Sogea.RilevamentoProduzione, possiamo espandere i seguenti concetti architetturali:

**Domain-Driven Design (DDD)**:
- Il microservizio implementa chiaramente i principi DDD attraverso la separazione in namespace come Domain, Abstractions e Commands
- Il namespace Domain contiene probabilmente le entità di dominio, aggregati, value objects e domain services che rappresentano il nucleo del business
- Le Abstractions forniscono interfacce e contratti che definiscono comportamenti senza implementazioni concrete
- Questa separazione permette di mantenere il dominio al centro dell'applicazione, isolandolo dalle preoccupazioni tecniche

**Command Query Responsibility Segregation (CQRS)**:
- La separazione esplicita tra Commands e Queries evidenzia l'implementazione del pattern CQRS
- I Commands (in Sogea.RilevamentoProduzione.Commands) gestiscono le operazioni di scrittura e modifica dello stato
- Le Queries (in Sogea.RilevamentoProduzione.Queries) gestiscono le operazioni di lettura dei dati
- I QueryHandlers specifici (Sogea.RilevamentoProduzione.QueriesHandlers) elaborano le query e interagiscono con PostgreSQL, suggerendo un'implementazione completa del pattern

**Event Sourcing**:
- Il namespace Events indica l'implementazione di Event Sourcing, dove le modifiche allo stato sono registrate come eventi
- Gli eventi rappresentano fatti immutabili che sono accaduti nel sistema
- Questa architettura permette di ricostruire lo stato del sistema riapplicando gli eventi in sequenza
- La presenza di questo modulo suggerisce che il sistema mantiene un log degli eventi come fonte di verità

**Data Transfer Objects (DTOs)**:
- Il namespace DTOs (Sogea.RilevamentoProduzione.DTOs) contiene oggetti utilizzati per trasferire dati tra i diversi livelli dell'applicazione
- I DTOs sono oggetti immutabili che incapsulano dati per il trasferimento tra componenti
- Separano la rappresentazione dei dati nel dominio dalla loro rappresentazione per la comunicazione, prevenendo l'esposizione diretta delle entità di dominio

**Handlers**:
- I QueriesHandlers (Sogea.RilevamentoProduzione.QueriesHandlers) implementano la logica di gestione delle query
- Probabilmente il sistema utilizza anche command handlers (non visibili direttamente ma presumibilmente presenti in Commands)
- I handlers rappresentano il punto di contatto tra l'infrastruttura e il dominio, traducendo le richieste in operazioni sul dominio
- La presenza di handlers specifici per PostgreSQL (Sogea.RilevamentoProduzione.QueriesHandlers.PostgreSQL) indica un'implementazione per database specifici, permettendo flessibilità e potenziali sostituzioni

Questa struttura modulare facilita la manutenzione, il testing e la scalabilità del microservizio, consentendo modifiche e aggiornamenti localizzati senza impattare l'intero sistema. L'architettura complessiva suggerisce un'implementazione matura di principi di progettazione avanzati orientati ai microservizi.

sull'implementazione della webapi
i microservizi sono intrinsecamente caratterizzati da lavori di integration, ossia di comunicazione tra le parti, infatti per la risoluzione del problema delle due letture, si è implementata una webapi che legge i dati sia da SAI che dal microservizio. 

Per spiegare che l'API effettua un'operazione di lettura, dovresti concentrarti sul metodo `FindByFaseAsync`, in particolare sulla parte che gestisce la chiamata REST. Ecco lo snippet più rilevante:

\begin{verbatim}
public async Task<OrdineProduzione> FindByFaseAsync(int ordineProduzioneFaseId)
{
  string url = this.Configuration.Server.Replace("{productionOrderId}", 
  ordineProduzioneFaseId.ToString());
  RestClient client = new RestClient(url);
  RestRequest request = new RestRequest(Method.GET);
  request.AddHeader("DITTA", this.Configuration.Ditta);
  IRestResponse response = await client.ExecuteAsync(request);
  if (response.IsSuccessful && response.Content != null)
  {
    RootDto rootDto = JsonConvert.DeserializeObject<RootDto>(response.Content);
    // ... elaborazione della risposta ...
  }
  return null;
}
\end{verbatim}

# Analisi dell'Operazione di Lettura nell'API di Rilevamento Produzione

Il componente fondamentale che implementa l'operazione di lettura all'interno dell'API è il metodo `FindByFaseAsync` della classe `OrdineProduzioneRepository`. Questo metodo esemplifica l'implementazione di un'operazione di recupero dati (Read) secondo il paradigma REST.

L'operazione di lettura si articola attraverso i seguenti passaggi:

1. **Costruzione dell'endpoint**: L'URL di destinazione viene dinamicamente generato sostituendo il parametro `{productionOrderId}` con l'identificativo della fase di produzione richiesta.

2. **Configurazione della richiesta HTTP**: Viene istanziato un client REST e configurata una richiesta di tipo GET, che per definizione nel protocollo HTTP rappresenta un'operazione di lettura non modificante.

3. **Contestualizzazione della richiesta**: L'header "DITTA" viene aggiunto per specificare il contesto aziendale della richiesta, consentendo al servizio di rispondere con i dati pertinenti.

4. **Esecuzione asincrona**: La richiesta viene eseguita in modalità asincrona (`await client.ExecuteAsync`), ottimizzando l'utilizzo delle risorse del sistema durante l'attesa della risposta.

5. **Elaborazione dei dati**: In caso di risposta positiva, i dati JSON ricevuti vengono deserializzati e trasformati in oggetti del dominio applicativo.

Questa implementazione rappresenta un esempio paradigmatico di pattern Repository, che isola la logica di business dalla complessità dell'accesso ai dati esterni, fornendo un'interfaccia coerente per il recupero delle informazioni relative agli ordini di produzione.

Per affrontare la complessa problematica della sincronizzazione dei dati, è stata implementata un'architettura specializzata basata sulla tecnologia Debezium, una piattaforma di Change Data Capture (CDC) open source, che viene dettagliatamente analizzata nella sezione dedicata alle tecnologie utilizzate nel progetto. Questa soluzione è stata applicata specificamente ai componenti del sistema che richiedevano un aggiornamento costante e affidabile dei dati tra diverse applicazioni o servizi.
L'architettura di sincronizzazione adottata ha integrato Debezium con RabbitMQ, quest'ultimo utilizzato come message broker per la gestione efficiente del flusso di informazioni. Questa combinazione tecnologica ha consentito la realizzazione di un sistema di code di messaggi altamente reattivo, in grado di catturare e propagare le modifiche ai dati nel momento stesso in cui queste venivano apportate nel sistema di origine.
Il principio operativo fondamentale di questa soluzione si basa sul meccanismo di Change Data Capture, attraverso il quale Debezium monitora continuamente il log delle transazioni del database, identifica le operazioni di inserimento, aggiornamento o eliminazione dei dati e trasforma queste informazioni in eventi che vengono successivamente instradati attraverso RabbitMQ verso i sistemi destinatari.
L'implementazione di questo pattern architetturale ha permesso di ottenere una sincronizzazione dei dati in tempo reale, eliminando i ritardi tipicamente associati ai tradizionali processi batch di aggiornamento e garantendo così una maggiore coerenza informativa tra i diversi componenti del sistema

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{BCS-Tessi//images/queue.PNG}
    \caption{RabbitMQ queue}
    \label{fig:queue}
\end{figure}

        
        \subsection{Verifica e validazione}
        Durante il processo di sviluppo software, ho adottato un approccio sistematico all'implementazione dei test unitari, integrandoli organicamente nel ciclo di sviluppo iterativo. L'esecuzione dei test unitari avveniva contestualmente all'implementazione di nuove funzionalità, seguendo la metodologia di sviluppo incrementale. Questo mi ha permesso di attuare una copertura totale di test del codice.
Le sessioni di sprint review costituivano un momento di verifica, durante il quale le funzionalità sviluppate erano sottoposte a un processo di validazione che coinvolgeva anche il Product Owner, garantendo così un controllo di qualità multidimensionale e una verifica della conformità rispetto ai requisiti iniziali.
Per quanto concerne la tipologia di test implementati, ho principalmente eseguito verifiche di integrazione per assicurare la corretta esposizione delle funzionalità sviluppate nell'ambiente server. A tal fine, ho utilizzato Swagger come strumento primario di verifica e documentazione delle API. Questo framework mi ha permesso di visualizzare in tempo reale l'effettivo funzionamento delle nuove implementazioni, offrendo un'interfaccia intuitiva per l'interazione con i servizi esposti.
La visualizzazione grafica fornita da Swagger ha rappresentato un elemento fondamentale nel processo di verifica, consentendomi di monitorare efficacemente l'integrazione delle nuove funzionalità nel sistema esistente e di identificare tempestivamente eventuali incongruenze o malfunzionamenti. 
\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{BCS-Tessi//images/swagger.PNG}
    \caption{Swagger}
    \label{fig:swagger}
\end{figure}

Il processo di validazione delle funzionalità sviluppate è stato caratterizzato da un approccio collegiale e multidisciplinare, coinvolgendo diverse figure professionali all'interno dell'organizzazione. La responsabilità primaria di tale validazione è stata assunta dal Product Owner, figura deputata alla verifica della conformità del prodotto rispetto ai requisiti di business, in sinergia con il Team Leader, che ha supervisionato gli aspetti tecnici dell'implementazione.
Un elemento distintivo del processo di validazione è stato il coinvolgimento attivo dell'intero team di sviluppo, creando così un contesto di revisione collettiva che ha favorito l'identificazione tempestiva di potenziali problematiche e l'ottimizzazione della qualità complessiva del prodotto. Questo approccio partecipativo si è concretizzato in particolare durante le sessioni di Sprint Review, eventi formali previsti dalla metodologia Agile.
Durante tali sessioni, la presenza simultanea di tutti i membri del team ha consentito un'analisi approfondita e multidimensionale delle funzionalità implementate. Questa modalità operativa ha permesso di sottoporre il prodotto a un esame critico da diverse prospettive professionali, garantendo una valutazione olistica che ha abbracciato sia gli aspetti funzionali che quelli tecnici dell'implementazione.
La Sprint Review ha rappresentato pertanto non solo un momento di verifica formale del lavoro svolto, ma anche un'occasione strutturata di confronto e condivisione, durante la quale il team nella sua interezza ha potuto osservare, analizzare e valutare sia le singole funzionalità implementate che il prodotto nella sua configurazione complessiva.


    \section{Risultati raggiunti}
        \subsection{Il microservizio}
        Descriverò le funzionalità del servizio estratto e l'efficacia dell'aggiornamento dei dati con il monolite.
        Scriverò una visione qualitativa degli obiettivi raggiunti, il loro allineamento al modello di dominio individuato.

        L'operazione di estrazione del microservizio dal sistema monolitico preesistente ha raggiunto l'obiettivo prefissato, conseguendo il risultato fondamentale di preservare integralmente le funzionalità originarie pur trasferendole in un'architettura indipendente. L'esito positivo di questa migrazione architetturale è evidenziato dalla piena operatività del componente estratto, ora funzionante come entità autonoma al di fuori del contesto monolitico in cui era originariamente integrato.
È doveroso precisare che il processo di estrazione ha richiesto l'implementazione di soluzioni tecniche che, sotto il profilo dell'eleganza architetturale, potrebbero essere considerate sub-ottimali. Tuttavia, tali compromessi sono stati consapevolmente accettati in considerazione dell'obiettivo primario del progetto, che consisteva nell'estrazione funzionale del microservizio piuttosto che nella realizzazione di un'architettura ideale dal punto di vista teorico.
Al termine del periodo di stage, il microservizio estratto ha raggiunto un livello di autonomia operativa significativo, pur mantenendo specifici canali di comunicazione con il sistema monolitico originario per garantire la continuità dei processi aziendali. Questa configurazione ha consentito al microservizio di assumere la responsabilità esclusiva della gestione dei rilevamenti e delle lavorazioni associate alle fasi produttive, interfacciandosi con il sistema di gestione degli ordini di produzione e delle relative fasi.
Come illustrato nella documentazione grafica di riferimento, l'architettura risultante dimostra la capacità del microservizio di operare come componente indipendente all'interno dell'ecosistema applicativo complessivo, rappresentando un significativo passo avanti nel processo di decomposizione del monolite verso un'architettura orientata ai microservizi.

        \begin{figure}[H]
            \centering
            \includegraphics[width=1\linewidth]{BCS-Tessi//images/FinalSwagger.PNG}
            \caption{Final Swagger}
            \label{fig:final-Swagger}
        \end{figure}
        
        L'estrazione del microservizio ha prodotto un significativo miglioramento nell'efficienza operativa dell'organizzazione, risolvendo problematiche strutturali che affliggevano il sistema precedente. La transizione architetturale ha permesso di superare le limitazioni imposte dall'approccio precedentemente adottato, basato sul pattern "batch delta copier", che rappresentava un significativo collo di bottiglia nei flussi informativi aziendali.
Nella configurazione precedente, l'aggiornamento dei dati avveniva attraverso procedure batch eseguite con cadenza giornaliera, imponendo un ritardo sistematico di 12 ore nella disponibilità delle informazioni aggiornate. Questa latenza costituiva un ostacolo significativo per gli operai, che si trovavano a lavorare con dati non allineati alla situazione corrente, compromettendo potenzialmente l'efficacia dei processi decisionali e operativi.
L'implementazione della tecnologia Debezium ha rivoluzionato questo paradigma, introducendo un meccanismo di aggiornamento in tempo reale che elimina la latenza informativa. Questo cambiamento ha permesso ai lavoratori di accedere immediatamente ai dati aggiornati, senza dover attendere l'esecuzione delle procedure batch notturne, con un conseguente incremento della reattività operativa e della qualità delle decisioni basate su informazioni tempestive.
È importante sottolineare che questa transizione verso un modello event-driven comporta un inevitabile compromesso in termini di consumo di risorse computazionali. La maggiore reattività del sistema si traduce in un più intenso utilizzo dell'infrastruttura IT, richiedendo un bilanciamento attento tra benefici operativi e costi infrastrutturali. In considerazione di questo trade-off, l'implementazione della sincronizzazione in tempo reale è stata strategicamente limitata ai soli dati per i quali la tempestività dell'aggiornamento rappresenta un requisito critico per i processi aziendali, ottimizzando così l'allocazione delle risorse disponibili.

        
        \subsection{Risultati quantitativi}
        Descriverò i risultati quantitativi raggiunti: sia riguardo alla documentazione effettivamente scritta, al codice sviluppato, eventuali \textit{report} e diagrammi, sia riguardo al miglioramento della \textit{performance} del sistema in generale, il \textit{tradeoff} tra miglioramenti e rallentamenti, in base agli obiettivi del progetto (e quindi del dominio).

        Durante il periodo di stage, ho conseguito con successo tre dei quattro obiettivi obbligatori inizialmente concordati, unitamente all'obiettivo facoltativo. L'obiettivo classificato come "desiderabile" non è stato affrontato, in seguito a una riconfigurazione strategica delle priorità progettuali. Tale riallineamento ha privilegiato lo sviluppo di una Proof of Concept (PoC), identificata come attività facoltativa (FA1), rispetto alla documentazione esaustiva dell'ecosistema dei servizi preesistenti e delle loro interdipendenze (OB3).
Questa riprioritizzazione delle attività si è rivelata funzionale al rispetto del vincolo temporale delle 304 ore allocate per l'esperienza formativa. L'efficiente gestione del tempo ha inoltre consentito l'estensione delle attività oltre il perimetro inizialmente definito, permettendo la realizzazione di un prototipo funzionale che rappresenta l'evoluzione naturale della Proof of Concept sviluppata.
I risultati tangibili prodotti durante il periodo di stage comprendono:

Un elaborato di analisi della letteratura scientifica concernente le metodologie di migrazione verso architetture a microservizi
Un documento tecnico sui pattern di migrazione, con particolare enfasi sugli approcci ritenuti più pertinenti per il contesto specifico di SogeaSoft
Un'analisi formale dei requisiti che sintetizza le esigenze funzionali e non funzionali identificate
Un corpus di 5826 linee di codice sorgente, sottoposte a processi di verifica e successivamente integrate nel branch di sviluppo del progetto



        
    \section{Sviluppi futuri}
    Racconterò di quanto il mio progetto di stage sia rilevante per SogeaSoft S.r.l. rispetto al loro obiettivo di migrazione completa del loro sistema verso un'architettura a microservizi.

    Il progetto di stage da me intrapreso riveste una particolare rilevanza per SogeaSoft in quanto si inserisce in un contesto di crescente esigenza di innovazione e miglioramento continuo del sistema software SAIonWeb. In seguito all’acquisizione da parte di Bluenext, come descritto nella Sezione 1.1, l’applicativo è destinato a gestire un numero sempre maggiore di clienti. Questa evoluzione comporta la necessità di aggiornamenti più frequenti e tempestivi, nonché l’adattamento del software alle specifiche esigenze aziendali e al relativo dominio di riferimento.  

Un aspetto cruciale risiede nella capacità di garantire ai clienti l’accesso ai dati in tempo reale, superando l’attuale limite che impone tempi di attesa di 24 ore per ottenere i dati del giorno precedente. Per raggiungere tale obiettivo, risulta imprescindibile scomporre l’architettura monolitica esistente e procedere verso una migrazione a un’architettura basata su microservizi.  
Immagino che la prima cosa che caratterizzerà anche i progetti di stage futuri sarà l'approfondimento della tecnologia Debezium, proprio a questo proposito. 
Ma non solo, anche l'esplorazione di nuovi pattern, dato che per ogni bounded context può corrispondere un microservizio, dunque il lavoro da fare è ancora molto. 

Tuttavia, il processo di migrazione si presenta come un percorso complesso e articolato, principalmente a causa della natura stessa del monolite SAI, il quale risulta stratificato e accoppiato a seguito di anni di sviluppo e aggiornamenti continui. La trasformazione dell’architettura monolitica in un insieme di microservizi richiederà dunque un notevole sforzo organizzativo e tecnico, nonché una pianificazione accurata e progressiva.  

In tale contesto, il progetto di stage ha costituito un primo passo significativo verso l’obiettivo più ampio della migrazione completa. Pur rappresentando solo una parte del progetto di lungo termine, il lavoro svolto ha permesso di delineare e testare approcci metodologici e tecnici che potranno essere riutilizzati e ampliati nelle fasi successive. La mia attività ha quindi contribuito a gettare le basi per un percorso di trasformazione che, nel medio-lungo periodo, porterà a una maggiore flessibilità e scalabilità del sistema SAIonWeb.
    
    
    